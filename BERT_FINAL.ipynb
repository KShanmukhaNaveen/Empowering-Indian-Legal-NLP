{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SJckfi-qgLPc"},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7OC6EMkWeWO7","outputId":"cc0db61d-1a32-4098-a41f-b996afdac085","executionInfo":{"status":"ok","timestamp":1729826559406,"user_tz":-330,"elapsed":3225,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow                         2.17.0\n","tensorflow-datasets                4.9.6\n","tensorflow-hub                     0.16.1\n","tensorflow-io-gcs-filesystem       0.37.1\n","tensorflow-metadata                1.16.1\n","tensorflow-probability             0.24.0\n","transformers                       4.44.2\n"]}],"source":["pip list | grep -E 'transformers|tensorflow'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oIHrGvrEeayo","outputId":"b5a871ff-ea93-4f6a-faa9-96823eaa8364","executionInfo":{"status":"ok","timestamp":1729826650122,"user_tz":-330,"elapsed":90727,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting transformers\n","  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Collecting tokenizers<0.21,>=0.20 (from transformers)\n","  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n","  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n","Collecting keras>=3.5.0 (from tensorflow)\n","  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard, tokenizers, keras, transformers, tensorflow\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.0\n","    Uninstalling tensorboard-2.17.0:\n","      Successfully uninstalled tensorboard-2.17.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.0\n","    Uninstalling tensorflow-2.17.0:\n","      Successfully uninstalled tensorflow-2.17.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.6.0 tensorboard-2.18.0 tensorflow-2.18.0 tokenizers-0.20.1 transformers-4.46.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras","tensorflow"]},"id":"4fe67053cacf4dd4b4baf3ffa4c3a083"}},"metadata":{}}],"source":["pip install --upgrade transformers tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iT8WAJ1irpW3","outputId":"b78377a8-08c5-40b5-f859-f4827d392954","executionInfo":{"status":"ok","timestamp":1729826654672,"user_tz":-330,"elapsed":4568,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9-FJuxTvJUi","outputId":"a232af0a-4d97-4336-f5cb-658f7ee9248b","executionInfo":{"status":"ok","timestamp":1729826669022,"user_tz":-330,"elapsed":14361,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from tqdm import tqdm, trange\n","from ast import literal_eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmSAA33LebBK"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvKh5jBjs8GT"},"outputs":[],"source":["import tensorflow as tf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ObkmLyMuGYp"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYF5S0YetOoN","executionInfo":{"status":"ok","timestamp":1729827447849,"user_tz":-330,"elapsed":11,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}},"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"71eb8cd5-3771-41d4-c60a-8c38563325cd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNExHSSGuOYZ","executionInfo":{"status":"error","timestamp":1729827810303,"user_tz":-330,"elapsed":654,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}},"colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"9d8834fd-4950-43f3-cd0c-3dd63cafedee"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/FYP 2024/DATASET/women_final.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8bd80122eab7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/FYP 2024/DATASET/women_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#-comment-classification-challenge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FYP 2024/DATASET/women_final.csv'"]}],"source":["df = pd.read_csv('/content/drive/MyDrive/FYP 2024/DATASET/women_final.csv') #-comment-classification-challenge\n","df.head()"]},{"cell_type":"code","source":["df[\"text\"][1]"],"metadata":{"id":"okoutPQcXOOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"8MPCL7oy99Pa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=df.dropna()"],"metadata":{"id":"7pthFN7w-tU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"VzVHmBqW-wBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0vKLBGD0voFf","executionInfo":{"status":"error","timestamp":1729827449476,"user_tz":-330,"elapsed":7,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}},"colab":{"base_uri":"https://localhost:8080/","height":176},"outputId":"b7453c03-c89f-46cc-c645-cdfb00ae332b"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1bebffa54bf3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unique comments: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Null values: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["print('Unique comments: ', df.text.nunique() == df.shape[0])\n","print('Null values: ', df.isnull().values.any())\n","df[df.isna().any(axis=1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eg4mODdTwXMf"},"outputs":[],"source":["print('average sentence length: ', df.text.str.split().str.len().mean())\n","print('stdev sentence length: ', df.text.str.split().str.len().std())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3Jakuy6xAT0"},"outputs":[],"source":["cols = df.columns\n","label_cols = list(cols[2:])\n","num_labels = len(label_cols)\n","print('Label columns: ', label_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3f7zV3xxGSL"},"outputs":[],"source":["print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n","print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_l0FJhGxL3p"},"outputs":[],"source":["df = df.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA2yY3g8xQ6d"},"outputs":[],"source":["df['one_hot_labels'] = list(df[label_cols].values)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CK_LKzCxX7Q"},"outputs":[],"source":["labels = list(df.one_hot_labels.values)\n","comments = list(df.text.values)"]},{"cell_type":"code","source":["import os\n","current_dir = os.getcwd()\n","print(os.listdir(current_dir))"],"metadata":{"id":"mOQ6ndZMvR1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KbPr9gbxf6l","executionInfo":{"status":"ok","timestamp":1729827459726,"user_tz":-330,"elapsed":8653,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}},"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["6e771eab0f764a7a8b46fb575fa68538","ceb8a321214b4471a59bc6b3ea36006d","af742641d3bd44a68ecaef96720bba8e","cd93e417f9c24a82bd440a76b808a9cd","28f78cc510e0475bbf44f5f66c241cb9","14bee5b10bf64b6ab6ec22ab4a2af1fd","5ff04d74db1c4fdeb01aa0be4f4bffba","d8f13eea06ec48d9bd50021cc51e675d","9daa57c482f842fd8894326e879b16e2","0983a996a1ca44159c35c937accd6c13","1fc85f86e01e40e68be47475ee380699","f4a8926de9c74fe0a7e914856a8369a4","dc5bf63cb17b46c1a8e7a876103ece24","c8092851d6204199bfb19a97e767d71e","f458f5095d5640bea72363b7654e6b69","6ddac309c95347abaa7693c1503e1602","f2dad2ac25154d13baa31e5305e7db45","19add7471c234bd8a76edcc54b66504d","6282867e1dca4d3996b456f55d290393","24eb615e529349568fb85c452f7b3030","7b47a0ec917049be9d2be7399f241f02","c37bac5b34c142fabd9c42b226ec652c","87bbf21d116f42958c24ae7f8bba1188","029b46314fcb41069c9ef55f56cd6fc7","5a88af92aa864a43b486c7dfe0eba932","a408bbce7da04b7a875c16b4dab90fbc","6321ed89701344a1b6137fe949206707","64fe3cc4764f4c7982553e29ace99c71","4e1ebd13ddd2424b9e774f6e46fb99f3","5e0af77b691e4e7e97e5d819cd7a67ce","5ffdac9ce54b4974a6722a022d4f6ff8","17129125da0d4995be62196e80e8b7ff","f25f303f93784f18bcfe1acccd696db1","f218c80d06b64f65a64acb101382dba8","7d3ab4bc170547cb8309ee59e25dd7d2","f8b504ff637c4debaa78b14c152b81cd","847f8b6f7b5e454eb7a84d018e18616f","7f6a7ec020834274aab0a0d8b26e65bb","dd47cbad98a3483ab875b2eb9d8e2cdd","3bc52f66df9f4244aaf6f76cefcfd854","d2fc86e744e1402a979af640c4b241bf","2ee230e1f1454fd18eba24b8dfc96383","37db9e0094c74a999dfabc34d677bebf","b93bf0682abe4c76b65b835f0d65bab2"]},"outputId":"9c48e799-b150-4489-8282-6845585bd074"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e771eab0f764a7a8b46fb575fa68538"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a8926de9c74fe0a7e914856a8369a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87bbf21d116f42958c24ae7f8bba1188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f218c80d06b64f65a64acb101382dba8"}},"metadata":{}}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA0dIUDMxwKd","executionInfo":{"status":"error","timestamp":1729827460499,"user_tz":-330,"elapsed":776,"user":{"displayName":"Jeshmitha J","userId":"05885647697177533439"}},"colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"18f73767-d7ce-487d-9618-4d0c1d86ad15"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'comments' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-be9b25d04811>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tokenizer's encoding method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizer outputs: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"]}],"source":["max_length = 100\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n","encodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n","print('tokenizer outputs: ', encodings.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EfRuCIvcyw1c"},"outputs":[],"source":["input_ids = encodings['input_ids'] # tokenized and encoded sentences\n","token_type_ids = encodings['token_type_ids'] # token type ids\n","attention_masks = encodings['attention_mask'] # attention masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCWnMTM8y3cy"},"outputs":[],"source":["# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n","label_counts = df.one_hot_labels.astype(str).value_counts()\n","one_freq = label_counts[label_counts==1].keys()\n","one_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n","print('df label indices with only one instance: ', one_freq_idxs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oS6IvwVEy4j0"},"outputs":[],"source":["# Gathering single instance inputs to force into the training set after stratified split\n","one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n","one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n","one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n","one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUkfxO-ky8Zc"},"outputs":[],"source":["\n","train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n","                                                            random_state=2020, test_size=0.30, stratify = labels)\n","\n","# Add one frequency data to train data\n","train_inputs.extend(one_freq_input_ids)\n","train_labels.extend(one_freq_labels)\n","train_masks.extend(one_freq_attention_masks)\n","train_token_types.extend(one_freq_token_types)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","train_token_types = torch.tensor(train_token_types)\n","\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","validation_token_types = torch.tensor(validation_token_types)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lv0zY7vczBR9"},"outputs":[],"source":["batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0k0zzp1zSl2"},"outputs":[],"source":["torch.save(validation_dataloader,'validation_data_loader')\n","torch.save(train_dataloader,'train_data_loader')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YPWxDKEzVoo"},"outputs":[],"source":["from transformers import BertForSequenceClassification\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjIupmzO0B7E"},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdh3qROb0CFM"},"outputs":[],"source":["# Load model, the pretrained model will include a single linear classification layer on top for classification.\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtVxwinq0NsD"},"outputs":[],"source":["# setting custom optimization parameters. You may implement a scheduler here as well.\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kO8xqKcE0Rn7"},"outputs":[],"source":["from transformers import AdamW\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5vBswtY0URe"},"outputs":[],"source":["optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n","# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EspjBiup0XAu"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-Iz8soHB-Yi"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKibvEcPEALH"},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score\n","\n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","train_f1_set = []\n","train_acc_set = []\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 5\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","\n","    # Training\n","\n","    # Set our model to training mode (as opposed to evaluation mode)\n","    model.train()\n","\n","    # Tracking variables\n","    tr_loss = 0  # running loss\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    train_preds, train_labels = [], []\n","    threshold=0.50\n","\n","    for step, batch in enumerate(train_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","        # Clear out the gradients (by default they accumulate)\n","        optimizer.zero_grad()\n","\n","        # Forward pass for multilabel classification\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","        logits = outputs[0]\n","        loss_func = BCEWithLogitsLoss()\n","        loss = loss_func(logits.view(-1, num_labels), b_labels.type_as(logits).view(-1, num_labels))  # convert labels to float for calculation\n","        train_loss_set.append(loss.item())\n","\n","        # Backward pass\n","        loss.backward()\n","        # Update parameters and take a step using the computed gradient\n","        optimizer.step()\n","\n","        # Update tracking variables\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","        # Extend the lists with current batch predictions and labels\n","        pred_bools = [pl > threshold for pl in logits.detach().cpu().numpy()]\n","        train_preds.extend(pred_bools)\n","        train_labels.extend(b_labels.cpu().numpy())\n","\n","    # Calculate train accuracy and F1 score\n","    train_acc = accuracy_score(train_labels, train_preds) * 100\n","    train_f1 = f1_score(train_labels, train_preds, average='macro') * 100\n","\n","    train_f1_set.append(train_f1)\n","    train_acc_set.append(train_acc)\n","\n","    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))\n","    print(\"Train Accuracy: {:.2f}%\".format(train_acc))\n","\n","###############################################################################\n","\n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","model.eval()\n","\n","  # Variables to gather full output\n","logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","  # Predict\n","for i, batch in enumerate(validation_dataloader):\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    with torch.no_grad():\n","      # Forward pass\n","      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      b_logit_pred = outs[0]\n","      pred_label = torch.sigmoid(b_logit_pred)\n","\n","      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","      pred_label = pred_label.to('cpu').numpy()\n","      b_labels = b_labels.to('cpu').numpy()\n","\n","    tokenized_texts.append(b_input_ids)\n","    logit_preds.append(b_logit_pred)\n","    true_labels.append(b_labels)\n","    pred_labels.append(pred_label)\n","\n","  # Flatten outputs\n","pred_labels = [item for sublist in pred_labels for item in sublist]\n","true_labels = [item for sublist in true_labels for item in sublist]\n","\n","  # Calculate Accuracy\n","threshold = 0.50\n","pred_bools = [pl>threshold for pl in pred_labels]\n","true_bools = [tl==1 for tl in true_labels]\n","\n","val_f1macro_accuracy = f1_score(true_bools,pred_bools,average='macro')*100\n","val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n","\n","print('Validation Accuracy: ', val_flat_accuracy)"]},{"cell_type":"code","source":["test_df = pd.read_csv('/content/drive/MyDrive/FYP 2024/DATASET/women_final.csv')\n","test_label_cols = list(test_df.columns[2:])\n","print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n","print('Same columns between train and test: ', label_cols == test_label_cols) #columns should be the same\n","test_df.head()"],"metadata":{"id":"sDzF1LWXBXBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/comments with -1 values\n","test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n","test_df.head()"],"metadata":{"id":"rhvf-y_pMEX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gathering input data\n","test_labels = list(test_df.one_hot_labels.values)\n","test_comments = list(test_df.text.values)"],"metadata":{"id":"cXkO7XppMKec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Encoding input data\n","test_encodings = tokenizer.batch_encode_plus(test_comments,max_length=max_length,pad_to_max_length=True)\n","test_input_ids = test_encodings['input_ids']\n","test_token_type_ids = test_encodings['token_type_ids']\n","test_attention_masks = test_encodings['attention_mask']"],"metadata":{"id":"uW7f18yIMcpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make tensors out of data\n","test_inputs = torch.tensor(test_input_ids)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(test_attention_masks)\n","test_token_types = torch.tensor(test_token_type_ids)\n","# Create test dataloader\n","test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","# Save test dataloader\n","torch.save(test_dataloader,'test_data_loader')"],"metadata":{"id":"Dv3M52IeMmzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test\n","\n","# Put model in evaluation mode to evaluate loss on the validation set\n","model.eval()\n","\n","#track variables\n","logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","# Predict\n","for i, batch in enumerate(test_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","  with torch.no_grad():\n","    # Forward pass\n","    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    b_logit_pred = outs[0]\n","    pred_label = torch.sigmoid(b_logit_pred)\n","\n","    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","    pred_label = pred_label.to('cpu').numpy()\n","    b_labels = b_labels.to('cpu').numpy()\n","\n","  tokenized_texts.append(b_input_ids)\n","  logit_preds.append(b_logit_pred)\n","  true_labels.append(b_labels)\n","  pred_labels.append(pred_label)\n","\n","# Flatten outputs\n","tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n","pred_labels = [item for sublist in pred_labels for item in sublist]\n","true_labels = [item for sublist in true_labels for item in sublist]\n","# Converting flattened binary values to boolean values\n","true_bools = [tl==1 for tl in true_labels]"],"metadata":{"id":"qw1PqHIsTt9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n","\n","\n","# Print and save classification report\n","print('Test F1 macro Accuracy: ', f1_score(true_bools, pred_bools,average='macro'))\n","print('Test Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n","clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n","pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n","print(clf_report)"],"metadata":{"id":"EaCY_4XCUI6_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx2label = dict(zip(range(12),label_cols))\n","print(idx2label)\n","\n"],"metadata":{"id":"vobuVxsFQL--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n","true_label_idxs, pred_label_idxs=[],[]\n","for vals in true_bools:\n","  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n","for vals in pred_bools:\n","  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"],"metadata":{"id":"nPye06K4QN_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gathering vectors of label names using idx2label\n","true_label_texts, pred_label_texts = [], []\n","for vals in true_label_idxs:\n","  if vals:\n","    true_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    true_label_texts.append(vals)\n","\n","for vals in pred_label_idxs:\n","  if vals:\n","    pred_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    pred_label_texts.append(vals)"],"metadata":{"id":"LofA5BJjQP3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"oQEZK3bp72M_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_data = {'true_labels': true_label_texts, 'pred_labels': pred_label_texts}\n","\n","with open('vector.pkl', 'wb') as f:\n","    pickle.dump(vector_data, f)\n"],"metadata":{"id":"Ow4T087z70PV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decoding input ids to comment text\n","texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"],"metadata":{"id":"v_SLf3kIQSIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Converting lists to df\n","comparisons_df = pd.DataFrame({'text': texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n","comparisons_df.to_csv('comparisons.csv')\n","comparisons_df.head(50)"],"metadata":{"id":"6OFzf4cfQ1n4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate Accuracy - maximize F1 accuracy by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n","\n","macro_thresholds = np.array(range(1,10))/10\n","\n","f1_results, flat_acc_results = [], []\n","for th in macro_thresholds:\n","  pred_bools = [pl>th for pl in pred_labels]\n","  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n","  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","  f1_results.append(test_f1_accuracy)\n","  flat_acc_results.append(test_flat_accuracy)\n","\n","best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n","\n","micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n","\n","f1_results, flat_acc_results = [], []\n","for th in micro_thresholds:\n","  pred_bools = [pl>th for pl in pred_labels]\n","  test_f1_accuracy = f1_score(true_bools,pred_bools,average='macro')\n","  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","  f1_results.append(test_f1_accuracy)\n","  flat_acc_results.append(test_flat_accuracy)\n","\n","best_f1_idx = np.argmax(f1_results) #best threshold value\n","\n","# Printing and saving classification report\n","print('Best Threshold: ', micro_thresholds[best_f1_idx])\n","print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n","print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n","\n","best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n","clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n","pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n","print(clf_report_optimized)"],"metadata":{"id":"naA3FyfsU3MW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install optuna"],"metadata":{"id":"in7XW1laRksJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import optuna\n","from sklearn.metrics import f1_score, accuracy_score, classification_report\n","\n","# Define objective function for optimization\n","def objective(trial):\n","    # Define macro_thresholds on the order of e^-1\n","    macro_threshold = trial.suggest_uniform('macro_threshold', 0.1, 0.9)\n","\n","    # Calculate F1 score and accuracy for each macro_threshold\n","    f1_results, flat_acc_results = [], []\n","    for th in [macro_threshold]:\n","        pred_bools = [pl > th for pl in pred_labels]\n","        test_f1_accuracy = f1_score(true_bools, pred_bools, average='micro')\n","        test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","        f1_results.append(test_f1_accuracy)\n","        flat_acc_results.append(test_flat_accuracy)\n","\n","    # Find the best macro threshold\n","    best_macro_th = macro_thresholds[np.argmax(f1_results)]\n","\n","    # Calculate micro_thresholds on the order of e^-2\n","    micro_thresholds = np.linspace(best_macro_th, best_macro_th + 0.09, num=10)\n","\n","    # Calculate F1 score and accuracy for each micro_threshold\n","    f1_results, flat_acc_results = [], []\n","    for th in micro_thresholds:\n","        pred_bools = [pl > th for pl in pred_labels]\n","        test_f1_accuracy = f1_score(true_bools, pred_bools, average='macro')\n","        test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","        f1_results.append(test_f1_accuracy)\n","        flat_acc_results.append(test_flat_accuracy)\n","\n","    # Get the best F1 score index\n","    best_f1_idx = np.argmax(f1_results)\n","\n","    # Return the negative of F1 score as Optuna aims to minimize the objective\n","    return -f1_results[best_f1_idx]\n","\n","# Optimize using Optuna\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","\n","# Get the best parameters\n","best_macro_threshold = study.best_params['macro_threshold']\n","\n","# Use the best macro threshold to calculate micro thresholds\n","best_micro_thresholds = np.linspace(best_macro_threshold, best_macro_threshold + 0.09, num=10)\n","\n","# Evaluate using the best micro thresholds\n","f1_results, flat_acc_results = [], []\n","for th in best_micro_thresholds:\n","    pred_bools = [pl > th for pl in pred_labels]\n","    test_f1_accuracy = f1_score(true_bools, pred_bools, average='macro')\n","    test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","    f1_results.append(test_f1_accuracy)\n","    flat_acc_results.append(test_flat_accuracy)\n","\n","# Get the index of the best F1 score\n","best_f1_idx = np.argmax(f1_results)\n","\n","# Print and save classification report\n","print('Best Threshold: ', best_micro_thresholds[best_f1_idx])\n","print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n","print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n","\n","best_pred_bools = [pl > best_micro_thresholds[best_f1_idx] for pl in pred_labels]\n","clf_report_optimized = classification_report(true_bools, best_pred_bools, target_names=label_cols)\n","with open('classification_report_optimized.txt', 'w') as f:\n","    f.write(clf_report_optimized)\n","print(clf_report_optimized)\n"],"metadata":{"id":"fFoHBtkmRiJ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","# Save the Optuna study object\n","with open('study.pkl', 'wb') as f:\n","    pickle.dump(study, f)\n","\n","# Save the best parameters\n","best_params = {\n","    'best_macro_threshold': best_macro_threshold,\n","    'best_micro_thresholds': best_micro_thresholds\n","}\n","with open('best_params.pkl', 'wb') as f:\n","    pickle.dump(best_params, f)\n"],"metadata":{"id":"OLRr0oTp85VX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","# Save the model, tokenizer, and optimizer parameters\n","torch.save(model.state_dict(), 'model.pth')  # Save the model\n","with open('tokenizer.pkl', 'wb') as f:\n","    pickle.dump(tokenizer, f)  # Save the tokenizer\n","with open('optimizer_params.pkl', 'wb') as f:\n","    pickle.dump(optimizer_grouped_parameters, f)  # Save the optimizer parameters\n"],"metadata":{"id":"cuaE8mW79Nhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import pickle\n","\n","# Load the BERT model\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","model.load_state_dict(torch.load('model.pth'))\n","model.eval()\n","\n","# Load the tokenizer\n","with open('tokenizer.pkl', 'rb') as f:\n","    tokenizer = pickle.load(f)\n","\n","# Tokenize the input text\n","text = \"Heard learned counsel for the applicant and learned AGA for the State. By means of this application, the applicant, who is involved in Case Crime No. __ of __, under sections __ IPC, police station Kaptanganj, district Kushinagar, is seeking enlargement on bail during the trial. Submission made by learned counsel for the applicant is that FIR was registered under sections __ IPC against three accused persons: Smt. Kaushalya Devi (mother-in-law), Ajay Yadav (husband), and Rahul Yadav (dewar). Further, before issuing the release order, the sureties should be verified: (i) the applicant shall file an undertaking to the effect that he shall not seek any adjournment on the date fixed for evidence when the witnesses are present in court. In case of default of this condition, it shall be open for the trial court to treat it as abuse of liberty of bail and pass orders in accordance with law; (ii) the applicant shall remain present before the trial court on each date fixed, either personally.\"\n","inputs = tokenizer(text, padding=True, truncation=True, max_length=100, return_tensors=\"pt\")\n","\n","# Get the model predictions\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","    logits = outputs.logits\n","\n","# Convert logits to probabilities\n","probs = torch.nn.functional.softmax(logits, dim=1)[0]\n","\n","# Print the prediction scores\n","print(\"Prediction scores:\", probs)\n"],"metadata":{"id":"YTG5a-dXAXWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the index of the maximum score\n","predicted_label_idx = torch.argmax(probs).item()\n","\n","# Map the index to the label using idx2label\n","predicted_label = idx2label[predicted_label_idx]\n","\n","# Print the predicted label and its corresponding penal code\n","print(\"Predicted label:\", predicted_label)\n"],"metadata":{"id":"QeMJLbVdAypT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Nxy57tG_wD7m"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6e771eab0f764a7a8b46fb575fa68538":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ceb8a321214b4471a59bc6b3ea36006d","IPY_MODEL_af742641d3bd44a68ecaef96720bba8e","IPY_MODEL_cd93e417f9c24a82bd440a76b808a9cd"],"layout":"IPY_MODEL_28f78cc510e0475bbf44f5f66c241cb9"}},"ceb8a321214b4471a59bc6b3ea36006d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14bee5b10bf64b6ab6ec22ab4a2af1fd","placeholder":"​","style":"IPY_MODEL_5ff04d74db1c4fdeb01aa0be4f4bffba","value":"tokenizer_config.json: 100%"}},"af742641d3bd44a68ecaef96720bba8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8f13eea06ec48d9bd50021cc51e675d","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9daa57c482f842fd8894326e879b16e2","value":48}},"cd93e417f9c24a82bd440a76b808a9cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0983a996a1ca44159c35c937accd6c13","placeholder":"​","style":"IPY_MODEL_1fc85f86e01e40e68be47475ee380699","value":" 48.0/48.0 [00:00&lt;00:00, 610B/s]"}},"28f78cc510e0475bbf44f5f66c241cb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14bee5b10bf64b6ab6ec22ab4a2af1fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ff04d74db1c4fdeb01aa0be4f4bffba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8f13eea06ec48d9bd50021cc51e675d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9daa57c482f842fd8894326e879b16e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0983a996a1ca44159c35c937accd6c13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fc85f86e01e40e68be47475ee380699":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4a8926de9c74fe0a7e914856a8369a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc5bf63cb17b46c1a8e7a876103ece24","IPY_MODEL_c8092851d6204199bfb19a97e767d71e","IPY_MODEL_f458f5095d5640bea72363b7654e6b69"],"layout":"IPY_MODEL_6ddac309c95347abaa7693c1503e1602"}},"dc5bf63cb17b46c1a8e7a876103ece24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2dad2ac25154d13baa31e5305e7db45","placeholder":"​","style":"IPY_MODEL_19add7471c234bd8a76edcc54b66504d","value":"vocab.txt: 100%"}},"c8092851d6204199bfb19a97e767d71e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6282867e1dca4d3996b456f55d290393","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24eb615e529349568fb85c452f7b3030","value":231508}},"f458f5095d5640bea72363b7654e6b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b47a0ec917049be9d2be7399f241f02","placeholder":"​","style":"IPY_MODEL_c37bac5b34c142fabd9c42b226ec652c","value":" 232k/232k [00:00&lt;00:00, 542kB/s]"}},"6ddac309c95347abaa7693c1503e1602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2dad2ac25154d13baa31e5305e7db45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19add7471c234bd8a76edcc54b66504d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6282867e1dca4d3996b456f55d290393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24eb615e529349568fb85c452f7b3030":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b47a0ec917049be9d2be7399f241f02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c37bac5b34c142fabd9c42b226ec652c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87bbf21d116f42958c24ae7f8bba1188":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_029b46314fcb41069c9ef55f56cd6fc7","IPY_MODEL_5a88af92aa864a43b486c7dfe0eba932","IPY_MODEL_a408bbce7da04b7a875c16b4dab90fbc"],"layout":"IPY_MODEL_6321ed89701344a1b6137fe949206707"}},"029b46314fcb41069c9ef55f56cd6fc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64fe3cc4764f4c7982553e29ace99c71","placeholder":"​","style":"IPY_MODEL_4e1ebd13ddd2424b9e774f6e46fb99f3","value":"tokenizer.json: 100%"}},"5a88af92aa864a43b486c7dfe0eba932":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e0af77b691e4e7e97e5d819cd7a67ce","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ffdac9ce54b4974a6722a022d4f6ff8","value":466062}},"a408bbce7da04b7a875c16b4dab90fbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17129125da0d4995be62196e80e8b7ff","placeholder":"​","style":"IPY_MODEL_f25f303f93784f18bcfe1acccd696db1","value":" 466k/466k [00:00&lt;00:00, 1.08MB/s]"}},"6321ed89701344a1b6137fe949206707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64fe3cc4764f4c7982553e29ace99c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1ebd13ddd2424b9e774f6e46fb99f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e0af77b691e4e7e97e5d819cd7a67ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ffdac9ce54b4974a6722a022d4f6ff8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17129125da0d4995be62196e80e8b7ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f25f303f93784f18bcfe1acccd696db1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f218c80d06b64f65a64acb101382dba8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d3ab4bc170547cb8309ee59e25dd7d2","IPY_MODEL_f8b504ff637c4debaa78b14c152b81cd","IPY_MODEL_847f8b6f7b5e454eb7a84d018e18616f"],"layout":"IPY_MODEL_7f6a7ec020834274aab0a0d8b26e65bb"}},"7d3ab4bc170547cb8309ee59e25dd7d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd47cbad98a3483ab875b2eb9d8e2cdd","placeholder":"​","style":"IPY_MODEL_3bc52f66df9f4244aaf6f76cefcfd854","value":"config.json: 100%"}},"f8b504ff637c4debaa78b14c152b81cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2fc86e744e1402a979af640c4b241bf","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ee230e1f1454fd18eba24b8dfc96383","value":570}},"847f8b6f7b5e454eb7a84d018e18616f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37db9e0094c74a999dfabc34d677bebf","placeholder":"​","style":"IPY_MODEL_b93bf0682abe4c76b65b835f0d65bab2","value":" 570/570 [00:00&lt;00:00, 12.9kB/s]"}},"7f6a7ec020834274aab0a0d8b26e65bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd47cbad98a3483ab875b2eb9d8e2cdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bc52f66df9f4244aaf6f76cefcfd854":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2fc86e744e1402a979af640c4b241bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ee230e1f1454fd18eba24b8dfc96383":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37db9e0094c74a999dfabc34d677bebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93bf0682abe4c76b65b835f0d65bab2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}